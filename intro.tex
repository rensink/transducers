\section{Introduction}
\label{sec:intro}

A principle that has often be proposed as a basis for system specification is that of \emph{declarative rules} that specify the ways in which the system may evolve, without prescribing in details how the evolution steps should be implemented. Such a rule typically includes an condition for its application, restricting the states in which it can be applied to those that satisfy that condition, as well as a specification of the state change that occurs when it is applied. Thus, the extension (i.e., the semantics) of the application condition is the set of states that satisfy it, and that of the state change is a binary relation over states.

In its pure form, the behaviour arising from such of a set of rules, given an initial state, is completely determined: it consists of all states that are reachable by the repeated application of rules, whenever they are applicable; the rule applications themselves can be captured by rule-labelled transitions. The resulting labelled transition system can then form the basis for further analysis, composition, or implementation.

However, when using rule-based specifications in practice, it is usually found to be desirable to add further structure on top of the pure rule system, with the purpose of explicitly scheduling the applicable rules. Such a schedule is essentially a second way of controlling rule applicability, besides the built-in application conditions of the rules themselves: for instance, in a schedule $a;b$ (where $a$ and $b$ are rules), rule $b$ is initially not considered for application, even if its own application condition is satisfied, whereas in $a\orelse b$, rule $b$ is only considered if $a$ is not applicable. Examples of formalisms and languages where pure declarative rules are augmented with a scheduling mechanism abound in the literature: for instance, for term rewriting \cite{Spoofax,Maude}, model transformation \cite{QVT}, graph transformation \cite{GG}; but also calculi like guarded commands \cite{GC,ChandyMisra}. If we consider a spectrum where rules can be more or less powerful, one might even regard any programming language as a scheduling mechanism for its basic statements, which are extremely simple rules, viz.\ assignments to variables.

In this paper, we regard schedules as separate artefacts that are \emph{imposed} on the transition systems generated by unscheduled rule application. This has the advantage of enabling the analysis of schedules in their own right, composing them, and checking them for, e.g., correctness and equivalence; all independently from the actual rules or transition system. From this point in the paper, we use the term \emph{control} to refer to this mechanism; in particular, we will present a calculus for control, the semantics of which will be modelled through so-called control automata. The imposition of a control automaton on a transition system again gives rise to a transition system, which is typically smaller than the original.

The concepts of control calculus and imposition are very close, and indeed directly inspired by, process calculus and parallel composition, in particular with the duality of input and output actions as originally proposed in CCS \cite{CCS} --- though in our setting we think of this duality as \emph{passive} (the transitions of the unscheduled rule system) versus \emph{active} (the control transitions). A related difference is that, in our setting, passive and active transitions are never mixed (it is always clear whether we are dealing with a control automaton or with a transition system), in contrast to input and output actions in CCS.

The actual contribution of this paper is the combination of two control operators that do not have a direct counterpart in CCS, although they have been studied individually in the literature on process algebras: namely, \emph{priority choice} (embodied in the example schedule $a\orelse b$ mentioned above) and \emph{atomic abstraction}. For the former, from the proposals reviewed in \cite{Handbook-priority}, our solution is essentially that of \cite{PriorityChoice}. The latter is a variation of \emph{action refinement}, many interpretations of which are likewise reviewed in \cite{Handbook-refinement}; however, here the emphasis lies on not on refinement but on its dual, abstraction. In fact, atomic abstraction is a method for the definition of composed rules: e.g., by defining $a\mapsto a_1;a_2$ we introduce a new rule $a$, the effect of which is the same as invoking the pre-existing $a_1$ and $a_2$ in succession: partial executions, in which $a_1$ is applied but leads to a state in which $a_2$ is not applicable (according to its own application condition), are ignored altogether. In other words, such composed rules have a transactional semantics (hence \emph{atomic} abstraction). Our formal treatment has more similarities to the recent \cite{Vaandrager} than to anything in \cite{Handbook-refinement}.

The combination of priority choice and atomic abstraction introduces a new aspect: namely, when imposing $a\orelse b$, meaning that $b$ is enabled if $a$ is not applicable, if $a\mapsto a_1;a_2$ is a composed rule then the transactional semantics dictates that $b$ is enabled not only if $a_1$ happens to be inapplicable altogether, but also $a_1$ \emph{is} applicable but its application can only lead to states in which $a_2$ is not applicable. Setting up the semantics of the control calculus and the imposition operator such that this aspect is dealt with correctly is the biggest challenge addressed by this paper.
